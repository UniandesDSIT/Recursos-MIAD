# Entrega 6.1 - Consultas estructuradas 

Durante las semanas 5, 6 y 7 vamos a estudiar estrategias de visualizaci√≥n de grandes vol√∫menes de datos (5), estudiar consultas estructuradas y extracci√≥n de conocimiento (6) y estrategias de flujos de datos (7) 

Son cuatro entregas incrementales y al acabarlas tendr√°n el material necesario para hacer la entrega del proyecto. As√≠ que vamos con la entrega 6.1!

![](misc/e61.png)

# Tabla de contenidos

* [Objetivo de la entrega](#objetivo-de-la-entrega)
* [Entregas](#entregas)
* [Ejemplo ideas y consejos](#ejemplo-ideas-y-consejos)
* [Insumos, datos y herramientas](#insumos-datos-y-herramientas)

# Objetivo de la entrega

Realizar un ejercicio pr√°ctico que nos ayude a cumplir el primero de los tres objetivos de la semana 6. 

1. Extraer informaci√≥n de una fuente de datos a partir de consultas. 

En resumen:

* Usar un lenguaje de consulta para relacionar y obtener informaci√≥n 

Realizar estos ejercicios los preparar√° para terminar el proyecto del curso.  

Para ello este documento contiene instrucciones con ejemplos y consejos. Adem√°s, encontrar√°n las indicaciones sobre los entregables y los insumos, datos y herramientas sugeridas para esta entrega.

Los ejemplos y consejos estar√°n marcados por el s√≠mbolo üí°  

Las entregas marcadas con el s√≠mbolo üìö y resumidas en la secci√≥n de entregas

# Entregas

A continuaci√≥n van a encontrar cada uno de los ejercicios con su respectiva explicaci√≥n y el entregable subrayado. Al final, el entregable es un archivo zip con almenos 2 archivos adentro:

* Un PDF con todos los textos, im√°genes y explicaciones.
* Uno o varios notebook (.ipynb) o archivo de c√≥digo (.py)

Manera de nombrar los archivos de resultados: S61_<login1> _<login2>_<login3>.zip

## 1. **Usar un lenguaje de consulta para relacionar y obtener informaci√≥n.**

üìö: Escribir en SQL, spark o pandas, consultas para responder a las siguientes preguntas. Y escribir la respuestas y hacer un reporte. 

CITIbikes quiere saber si la temperatura promedio de Nueva York afecta el numero de viajes y el alquiler de bicicletas. Para ello les vamos a mostrar informaci√≥n acerca de la temperatura y de los viajes. Pueden mostrarla independiente o en conjunto. Varios diagramas, an√°lisis y visi√≥n. 

Para poder encontrar informaci√≥n cuantitativa es importante saber consultar los datos  por SQL o con l√≠neas de c√≥digo usando la API de PySpark o de Pandas.  

Sin embargo la informaci√≥n cuantitativa no es suficiente por si sola. Tener listas de n√∫meros no nos sirve para nada si no podemos analizarlos tanto de forma cuantitava como cualitativa, con diagramas y modelos de correlaci√≥n. No solo tienen que encontrar valores sino indicar qu√© significan. Hay que mirar si un valor, aun siendo un m√≠nimo, o m√°ximo es un valor atipico o es representativo.

La sentencias no tienen que ser una √∫nica l√≠nea, pueden ser varias celdas en un notebook. Pero al final tiene que ser una sentencia v√°lida o c√≥digo v√°lido y devolver una respuesta. Escriban un comentario o texto corto sobre lo que responde la sentencia.

* ¬øEn qu√© semana, mes y en qu√© a√±o fue el momento m√°s caluroso? ¬øD√≥nde? 

Sentencia/c√≥digo y respuesta 

* ¬øCu√°ntas bicicletas fueron alquiladas en los 6 dias al rededor de ese momento m√°s caluroso (fecha ¬± 3 d√≠as) ? 

Sentencia/c√≥digo y respuesta 

* ¬øEn qu√© semana, mes y en qu√© a√±o fue el momento m√°s fr√≠o? 

Sentencia/c√≥digo y respuesta 

* ¬øCu√°ntas bicicletas fueron alquiladas en los 6 dias al rededor de ese momento m√°s fr√≠o (fecha ¬± 3 d√≠as)? 

Sentencia/c√≥digo y respuesta 

* ¬øCree usted que la diferencia entre bicicletas alquiladas tiene relaci√≥n con el clima? 

Ustedes pueden decidir si quieren hacer solo un diagrama o varios o solo un an√°lisis num√©rico pero deben sustentar su respuesta. Si hay una relacion entre el clima y el numero de viajes explique porqu√© y si no lo hay explique por qu√© no.

    Entregar: PDF con reporte. Notebook o c√≥digo mostrando la carga de datos, sentencias, respuestas y texto o comentarios en el c√≥digo.

Ver [notebook ejemplo](NotebookEjemploEntrega.ipynb) en esta misma semana. 

Si no pueden realizar el ejercicio en python*, pueden hacerlo en Tableau u otras herramientas si tienen licencias**. Si usan una herramienta donde tenga que escribirse c√≥digo se espera que lo entreguen (escrito, no captura de pantalla). De lo contrario, si deciden hacer las consultas y/o el diagrama por medio de una interfaz gr√°fica, el proceso debe estar muy bien documentado en su reporte en PDF y tendr√° una penalizaci√≥n.

<sub>* Cualquier librer√≠a de python esta bien incluso si no es Pandas o PySpark.</sub>

<sub>** Nosotros no somos responsables de las licencias ni de ayuda con herramientas diferentes a python o las herramientas especificadas en clase.</sub>

# Ejemplo, ideas y consejos

üí° **Dado que las respuestas son muy espec√≠ficas, voy a dar ejemplos en otro tipo de datos, el material de la semana es suficiente para realizar este ejercicio.**

Imaginemos una base de datos de [IMDB](https://www.imdb.com/) cuyo esquema es el siguiente. 

filme( **numf**, t√≠tulo,g√©nero, a√±o, duraci√≥n, presupuesto, director, salario) 
distribucion( **numf**, **numa**, papel, salario ) #actores por filme 
persona( *nump*, nombre, apellido, fecha_nacimiento ) 
actor( *numa*, agente, especialidad, altura, peso )  

Estos son ejemplos de consultas, y aclaro que esta no es la √∫nica forma de hacer las cosas, esta es solo una forma, asi como hablamos diferentes idiomas y diferentes vocabularios, todos programamos diferente:  

* Lista de todos los filmes

    * SQL
    `SELECT * FROM FILME`

    * Pandas
    `filme`

* Lista de todos los filmes que tienen una duraci√≥n de m√°s de 180 minutos 

    * SQL
    `SELECT * FROM FILME WHERE DURACION > 180 `

    * Pandas
    `filme[filme["duracion"] > 180]`

* Lista de todos los g√©neros de filme 

    * SQL
    `SELECT DISTINCT GENERO FROM FILME `
    * Pandas
    `filme["genero"].unique()`

* N√∫mero de filmes por g√©nero 

    * SQL
    `SELECT GENERO, COUNT(*) FROM FILME GROUP BY GENERO `
    * Pandas
    `filme[["titulo","genero"]].groupby(by="genero").count()`

* T√≠tulo de los filmes y los a√±os de los filmes m√°s largos 

    `SELECT TITULO, A√ëO FROM FILME WHERE DURACION = (SELECT MAX(DURACION) FROM FILME) `

* Nombre y apellido de los directores que han actuado en sus propios filmes 
    * forma plana: 

    `SELECT DISTINCT P.APELLIDO, P.NOMBRE FROM PERSONA P, FILME F, DISTRIBUCION D WHERE P.NUMP = F.DIRECTOR AND WHERE F.NUMF = D.NUMF AND D.NUMA = F.DIRECTOR `

    * Pandas
    ```
    ids_dirs=filme["director"]
    dir_n_act=[]
    for i, film in filme.iterrows(): 
        dist=distribucion[distribucion["numf"]=film["numf"]]
        if set(dist["numa"]) & set(ids_dirs):
            dir_n_act.append(film["director"])
    persona[persona["nump"].isin(dir_n_act)]
    ```

* Suma de salarios de los actores del film "Blade Runner"

    * forma plana: 

    `SELECT SUM(D.SALARIO) FROM FILME F, DISTRIBUCION D WHERE F.NUMF = D.NUMF AND F.TITULO = ‚ÄôBlade Runner‚Äô `


* Por cada pel√≠cula de Spielberg listar el t√≠tulo y a√±o y el total de de los salarios de actores 

    * forma plana 

    `SELECT F.TITULO, F.A√ëO, SUM(D.SALARIO) FROM FILME F, DISTRIBUCION D, PERSONA P WHERE F.NUMF = D.NUMF AND F.DIRECTOR = P.NUMP AND P.NOMBRE = ‚ÄôSpielberg‚Äô GROUP BY F.TITULO, F.A√ëO `


üí° Aqu√≠ hay algunos ejemplos de c√≥mo obtener algunos datos en PySpark

*  Encontrar minimos y maximos

`data.groupBy().agg(min("columna"),max("columna")).show()`

* mostrar una fila de ejemplo de forma vertical para legibilidad

`data.show(1,vertical=True)`

* tama√±o de un PySpark df

```
filas=data.count()
columnas=len(data.columns)
```

* dividir una fecha en partes
```
from pyspark.sql.functions import year, month, dayofmonth

newdf=data.select(data.DATE, year(data.DATE)
    .alias('ANNO'), month(data.DATE).alias('MES'), 
    dayofmonth(data.DATE).alias('DIA'))
```

Aqui hay un [vinculo](https://sparkbyexamples.com/pyspark/pyspark-sql-date-and-timestamp-functions/) para ir a un sitio web que explica algunas de las funciones relacionadas con manejo de fechas en PySpark.


# Insumos, datos y herramientas

Para estos talleres pueden usar las m√°quinas en GCP, pueden usar los dockers s2 o s3, no se necesitan m√°quinas nuevas. 

Estos son elementos comunes a todas las entregas y proyecto.

**Datos:**

Dado que esta es la segunda entrega del proyecto, se asume que los estudiantes ya tienen los datos del proyecto, es decir los datos de CITIBikes, las estaciones de clima y lugares de inter√©s. En este momento ya los estudiantes han realizado ETL con los datos y saben utilizar modelos de ML y estad√≠stica. Estos son los datos para trabajar en este proyecto.

**Herramientas:**

Los estudiantes pueden usar cualquier herramienta que les resulte familiar. Entre las herramientas que han visto en la maestr√≠a y en este curso se encuentran:


|         |            |
| ------------- |:-------------:|
|    **Lenguajes de programaci√≥n, consulta, hipertexto:** <br>Python <br>Javascript <br>SQL <br>HTML <br>     |      **Abrir y consultar bases de datos:**<br>Spark <br> Pandas <br>      |
|    **Diagramas est√°ticos:** <br>Matplotlib <br>Seaborn <br>D3 <br>    |      **Bases de datos:** <br>MySQL <br> MS-SQL <br> MongoDB <br>       |
|    **Tableros de control y diagramas din√°micos:** <br> Superset <br> Bokeh <br> D3 <br>    |      **An√°lisis num√©rico y estad√≠stica:** <br>Numpy <br>Scikit-learn <br>      |
|    **Aprendizaje de m√°quina:** <br>MLFlow <br> Pytorch <br> Tensorflow <br>     |      **An√°lisis de flujo de datos:** <br>Kafka <br>Spark <br>Amazon SQS <br>      |
